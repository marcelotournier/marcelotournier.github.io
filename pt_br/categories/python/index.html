<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#
" lang="pt_br">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Posts sobre python | Marcelo Tournier</title>
<link href="../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="canonical" href="https://marcelotournier.github.io/pt_br/categories/python/">
<!--[if lt IE 9]><script src="../../../assets/js/html5.js"></script><![endif]-->
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Pular para o conteúdo principal</a>

<!-- Menubar -->

<nav class="navbar navbar-expand-md static-top mb-4
navbar-dark
bg-dark
"><div class="container">
<!-- This keeps the margins nice -->
        <a class="navbar-brand" href="../../">

            <span id="blog-title">Marcelo Tournier</span>
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="bs-navbar">
            <ul class="navbar-nav mr-auto">
<li class="nav-item">
<a href="../blog/" class="nav-link">Blog</a>
                </li>
<li class="nav-item">
<a href="../code/" class="nav-link">Código</a>
                </li>
<li class="nav-item">
<a href="../../../pages/o-autor" class="nav-link">Sobre</a>
                </li>
<li class="nav-item">
<a href="https://www.linkedin.com/in/marcelotournier/" class="nav-link">LinkedIn</a>
                </li>
<li class="nav-item">
<a href="https://github.com/marcelotournier" class="nav-link">Github</a>

                
            </li>
</ul>
<ul class="navbar-nav navbar-right">
<li>
            </li>
<li class="nav-item"><a href="../../../" rel="alternate" hreflang="en" class="nav-link">English</a></li>

                
                    
                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        
        
        

    <header><h1>Posts sobre python</h1>
        <div class="metadata">
            

            

        </div>
    </header><div class="postindex">
    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../../blog/how-to-setup-pytorch-to-run-in-gpus-tpus-or-m1m2-macs/" class="u-url">How to setup PyTorch to run in GPUs, TPUs or M1/M2 Macs</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Marcelo Tournier
            </span></p>
            <p class="dateline">
            <a href="../../blog/how-to-setup-pytorch-to-run-in-gpus-tpus-or-m1m2-macs/" rel="bookmark">
            <time class="published dt-published" datetime="2023-01-03T07:19:46-05:00" itemprop="datePublished" title="2023-01-03 07:19">2023-01-03 07:19</time></a>
            </p>
                <p class="commentline">
    
    <a href="../../blog/how-to-setup-pytorch-to-run-in-gpus-tpus-or-m1m2-macs/#disqus_thread" data-disqus-identifier="cache/posts/how-to-setup-pytorch-to-run-in-gpus-tpus-or-m1m2-macs.html">Comentários</a>


        </p>
</div>
    </header><div class="e-content entry-content">
    <div class="code"><pre class="code literal-block"><span class="c1"># MIT License</span>
<span class="c1"># Copyright (c) 2022 Marcelo Benedet Tournier</span>
<span class="c1"># Permission is hereby granted, free of charge, to any person obtaining a copy</span>
<span class="c1"># of this software and associated documentation files (the "Software"), to deal</span>
<span class="c1"># in the Software without restriction, including without limitation the rights</span>
<span class="c1"># to use, copy, modify, merge, publish, distribute, sublicense, and/or sell</span>
<span class="c1"># copies of the Software, and to permit persons to whom the Software is</span>
<span class="c1"># furnished to do so, subject to the following conditions:</span>
<span class="c1"># The above copyright notice and this permission notice shall be included in all</span>
<span class="c1"># copies or substantial portions of the Software.</span>
<span class="c1"># THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR</span>
<span class="c1"># IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,</span>
<span class="c1"># FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE</span>
<span class="c1"># AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER</span>
<span class="c1"># LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,</span>
<span class="c1"># OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE</span>
<span class="c1"># SOFTWARE.</span>
<span class="c1">#</span>
<span class="c1"># PyTorch setup on Google colab</span>
<span class="c1"># </span>
<span class="c1"># If you are running this notebook in a Colab GPU/TPU environment,</span>
<span class="c1"># Paste this code block in the top cell of a Google Colab notebook.</span>
<span class="c1"># </span>
<span class="c1"># This shell script will install the pytorch TPU libraries needed for support.</span>
<span class="c1"># To debug, delete the "--quiet \" line from this cell.</span>
<span class="c1">#</span>
<span class="c1"># Change library versions below if needed:</span>
<span class="c1"># PyTorch setup on Google colab and M1/M2 macs</span>
<span class="c1"># </span>
<span class="c1"># If you are running this notebook in a Colab GPU/TPU environment,</span>
<span class="c1"># Paste this code block in the top cell of a Google Colab notebook.</span>
<span class="c1"># </span>
<span class="c1"># This shell script will install the pytorch TPU libraries needed for support.</span>
<span class="c1"># To debug, delete the "--quiet \" line from this cell.</span>
<span class="c1">#</span>
<span class="c1"># Change library versions below if needed:</span>
!TPU_AVAILABLE<span class="o">=</span><span class="k">$(</span>env<span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span>COLAB_TPU_ADDR<span class="w"> </span><span class="p">|</span><span class="w"> </span>wc<span class="w"> </span>-l<span class="k">)</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="se">\</span>
<span class="nv">CLOUD_TPU_CLIENT_VERSION</span><span class="o">=</span><span class="m">0</span>.10<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="se">\</span>
<span class="nv">PYTORCH_VERSION</span><span class="o">=</span><span class="m">1</span>.12.1<span class="w">  </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="se">\</span>
<span class="nv">TORCH_XLA_VERSION</span><span class="o">=</span><span class="m">1</span>.12<span class="w">  </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="se">\</span>
<span class="k">if</span><span class="w"> </span><span class="o">[</span><span class="w"> </span><span class="nv">$TPU_AVAILABLE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"1"</span><span class="w"> </span><span class="o">]</span><span class="w"> </span><span class="p">;</span><span class="se">\</span>
<span class="k">then</span><span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span><span class="se">\</span>
cloud-tpu-client<span class="o">==</span><span class="nv">$CLOUD_TPU_CLIENT_VERSION</span><span class="w"> </span><span class="se">\</span>
<span class="nv">torch</span><span class="o">==</span><span class="nv">$PYTORCH_VERSION</span><span class="w"> </span><span class="se">\</span>
https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-<span class="si">${</span><span class="nv">TORCH_XLA_VERSION</span><span class="si">}</span>-cp37-cp37m-linux_x86_64.whl<span class="w"> </span><span class="se">\</span>
--quiet<span class="w"> </span><span class="se">\</span>
<span class="p">;</span><span class="se">\</span>
<span class="k">fi</span>


import<span class="w"> </span>torch
import<span class="w"> </span>os

<span class="c1"># Verify if a GPU is available and if CUDA is properly installed</span>
<span class="nv">gpu_available</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>torch.cuda.is_available<span class="o">()</span>

<span class="c1"># Check for TPU availability in notebook environment</span>
<span class="nv">tpu_available</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>os.environ.get<span class="o">(</span><span class="s1">'COLAB_TPU_ADDR'</span><span class="o">)</span><span class="w"> </span>is<span class="w"> </span>not<span class="w"> </span>None

<span class="c1"># Run our device selection.</span>
<span class="c1"># Preference is for GPU, then TPU, then CPU:</span>
<span class="k">if</span><span class="w"> </span>gpu_available:
<span class="w">    </span><span class="nv">device</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>torch.device<span class="o">(</span><span class="s1">'cuda'</span><span class="o">)</span>

<span class="k">elif</span><span class="w"> </span>tpu_available:<span class="w"> </span>
<span class="w">    </span>import<span class="w"> </span>torch_xla<span class="w"> </span>
<span class="w">    </span>import<span class="w"> </span>torch_xla.core.xla_model<span class="w"> </span>as<span class="w"> </span>xm
<span class="w">    </span><span class="nv">device</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>xm.xla_device<span class="o">()</span>

<span class="c1"># run this in a M1/M2 mac:</span>
<span class="k">elif</span><span class="w"> </span><span class="o">(</span>torch.backends.mps.is_available<span class="o">())</span><span class="w"> </span><span class="p">&amp;</span><span class="w"> </span><span class="o">(</span>torch.backends.mps.is_built<span class="o">())</span>:
<span class="w">    </span><span class="nv">device</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>torch.device<span class="o">(</span><span class="s2">"mps"</span><span class="o">)</span>

<span class="k">else</span>:
<span class="w">    </span><span class="nv">device</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>torch.device<span class="o">(</span><span class="s1">'cpu'</span><span class="o">)</span>

print<span class="o">(</span><span class="s2">"device in use:"</span>,<span class="w"> </span>device,<span class="w"> </span><span class="s2">"\n---"</span><span class="o">)</span>

<span class="c1"># Print GPU info if it is available:</span>
<span class="k">if</span><span class="w"> </span>gpu_available:
<span class="w">    </span>print<span class="o">(</span>os.popen<span class="o">(</span><span class="s2">"nvidia-smi"</span><span class="o">)</span>.read<span class="o">())</span>
</pre></div>
    </div>
    </article>
</div>



    
       <script>var disqus_shortname="marcelo-tournier";(function(){var a=document.createElement("script");a.async=true;a.src="https://"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(a)}());</script><!--End of body content--><footer id="footer">
            Contents © 2023         <a href="mailto:marcelo@inova.life">Marcelo Tournier</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
            
            
        </footer>
</div>
</div>


        <script src="../../../assets/js/all-nocdn.js"></script><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
    </script>
</body>
</html>
