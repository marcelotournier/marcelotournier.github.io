<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#
" lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>How to setup PyTorch to run in GPUs, TPUs or M1/M2 Macs | Marcelo Tournier</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="canonical" href="https://marcelotournier.github.io/blog/how-to-setup-pytorch-to-run-in-gpus-tpus-or-m1m2-macs/">
<!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><meta name="author" content="Marcelo Tournier">
<link rel="prev" href="../rust-in-jupyter-notebooks/" title="How to add Rust support in Jupyter notebooks" type="text/html">
<meta property="og:site_name" content="Marcelo Tournier">
<meta property="og:title" content="How to setup PyTorch to run in GPUs, TPUs or M1/M2 Macs">
<meta property="og:url" content="https://marcelotournier.github.io/blog/how-to-setup-pytorch-to-run-in-gpus-tpus-or-m1m2-macs/">
<meta property="og:description" content='# MIT License
# Copyright (c) 2022 Marcelo Benedet Tournier
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "S'>
<meta property="og:type" content="article">
<meta property="article:published_time" content="2023-01-03T07:19:46-05:00">
<meta property="article:tag" content="code">
<meta property="article:tag" content="colab">
<meta property="article:tag" content="python">
<meta property="article:tag" content="pytorch">
<link rel="alternate" hreflang="pt_br" href="../../pt_br/blog/how-to-setup-pytorch-to-run-in-gpus-tpus-or-m1m2-macs/">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-expand-md static-top mb-4
navbar-dark
bg-dark
"><div class="container">
<!-- This keeps the margins nice -->
        <a class="navbar-brand" href="../../">

            <span id="blog-title">Marcelo Tournier</span>
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="bs-navbar">
            <ul class="navbar-nav mr-auto">
<li class="nav-item">
<a href="../../categories/blog/" class="nav-link">Blog</a>
                </li>
<li class="nav-item">
<a href="../../categories/code/" class="nav-link">Code</a>
                </li>
<li class="nav-item">
<a href="../../" class="nav-link">About</a>
                </li>
<li class="nav-item">
<a href="https://www.linkedin.com/in/marcelotournier/" class="nav-link">LinkedIn</a>
                </li>
<li class="nav-item">
<a href="https://github.com/marcelotournier" class="nav-link">Github</a>

                
            </li>
</ul>
<ul class="navbar-nav navbar-right">
<li>
            </li>
<li class="nav-item"><a href="../../pt_br/" rel="alternate" hreflang="pt_br" class="nav-link">Português</a></li>

                
                    
    
    <li class="nav-item">
    <a href="index.md" id="sourcelink" class="nav-link">Source</a>
    </li>


                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        
        
        
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">How to setup PyTorch to run in GPUs, TPUs or M1/M2 Macs</a></h1>

        <div class="metadata">
            <p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">
                    Marcelo Tournier
            </span></p>
            <p class="dateline">
            <a href="." rel="bookmark">
            <time class="published dt-published" datetime="2023-01-03T07:19:46-05:00" itemprop="datePublished" title="2023-01-03 07:19">2023-01-03 07:19</time></a>
            </p>
                <p class="commentline">
    
    <a href="#disqus_thread" data-disqus-identifier="cache/posts/how-to-setup-pytorch-to-run-in-gpus-tpus-or-m1m2-macs.html">Comments</a>


            
        </p>
<p class="sourceline"><a href="index.md" class="sourcelink">Source</a></p>

        </div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <div class="code"><pre class="code literal-block"><span class="c1"># MIT License</span>
<span class="c1"># Copyright (c) 2022 Marcelo Benedet Tournier</span>
<span class="c1"># Permission is hereby granted, free of charge, to any person obtaining a copy</span>
<span class="c1"># of this software and associated documentation files (the "Software"), to deal</span>
<span class="c1"># in the Software without restriction, including without limitation the rights</span>
<span class="c1"># to use, copy, modify, merge, publish, distribute, sublicense, and/or sell</span>
<span class="c1"># copies of the Software, and to permit persons to whom the Software is</span>
<span class="c1"># furnished to do so, subject to the following conditions:</span>
<span class="c1"># The above copyright notice and this permission notice shall be included in all</span>
<span class="c1"># copies or substantial portions of the Software.</span>
<span class="c1"># THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR</span>
<span class="c1"># IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,</span>
<span class="c1"># FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE</span>
<span class="c1"># AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER</span>
<span class="c1"># LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,</span>
<span class="c1"># OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE</span>
<span class="c1"># SOFTWARE.</span>
<span class="c1">#</span>
<span class="c1"># PyTorch setup on Google colab</span>
<span class="c1"># </span>
<span class="c1"># If you are running this notebook in a Colab GPU/TPU environment,</span>
<span class="c1"># Paste this code block in the top cell of a Google Colab notebook.</span>
<span class="c1"># </span>
<span class="c1"># This shell script will install the pytorch TPU libraries needed for support.</span>
<span class="c1"># To debug, delete the "--quiet \" line from this cell.</span>
<span class="c1">#</span>
<span class="c1"># Change library versions below if needed:</span>
<span class="c1"># PyTorch setup on Google colab and M1/M2 macs</span>
<span class="c1"># </span>
<span class="c1"># If you are running this notebook in a Colab GPU/TPU environment,</span>
<span class="c1"># Paste this code block in the top cell of a Google Colab notebook.</span>
<span class="c1"># </span>
<span class="c1"># This shell script will install the pytorch TPU libraries needed for support.</span>
<span class="c1"># To debug, delete the "--quiet \" line from this cell.</span>
<span class="c1">#</span>
<span class="c1"># Change library versions below if needed:</span>
!TPU_AVAILABLE<span class="o">=</span><span class="k">$(</span>env<span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span>COLAB_TPU_ADDR<span class="w"> </span><span class="p">|</span><span class="w"> </span>wc<span class="w"> </span>-l<span class="k">)</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="se">\</span>
<span class="nv">CLOUD_TPU_CLIENT_VERSION</span><span class="o">=</span><span class="m">0</span>.10<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="se">\</span>
<span class="nv">PYTORCH_VERSION</span><span class="o">=</span><span class="m">1</span>.12.1<span class="w">  </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="se">\</span>
<span class="nv">TORCH_XLA_VERSION</span><span class="o">=</span><span class="m">1</span>.12<span class="w">  </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="se">\</span>
<span class="k">if</span><span class="w"> </span><span class="o">[</span><span class="w"> </span><span class="nv">$TPU_AVAILABLE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"1"</span><span class="w"> </span><span class="o">]</span><span class="w"> </span><span class="p">;</span><span class="se">\</span>
<span class="k">then</span><span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span><span class="se">\</span>
cloud-tpu-client<span class="o">==</span><span class="nv">$CLOUD_TPU_CLIENT_VERSION</span><span class="w"> </span><span class="se">\</span>
<span class="nv">torch</span><span class="o">==</span><span class="nv">$PYTORCH_VERSION</span><span class="w"> </span><span class="se">\</span>
https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-<span class="si">${</span><span class="nv">TORCH_XLA_VERSION</span><span class="si">}</span>-cp37-cp37m-linux_x86_64.whl<span class="w"> </span><span class="se">\</span>
--quiet<span class="w"> </span><span class="se">\</span>
<span class="p">;</span><span class="se">\</span>
<span class="k">fi</span>


import<span class="w"> </span>torch
import<span class="w"> </span>os

<span class="c1"># Verify if a GPU is available and if CUDA is properly installed</span>
<span class="nv">gpu_available</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>torch.cuda.is_available<span class="o">()</span>

<span class="c1"># Check for TPU availability in notebook environment</span>
<span class="nv">tpu_available</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>os.environ.get<span class="o">(</span><span class="s1">'COLAB_TPU_ADDR'</span><span class="o">)</span><span class="w"> </span>is<span class="w"> </span>not<span class="w"> </span>None

<span class="c1"># Run our device selection.</span>
<span class="c1"># Preference is for GPU, then TPU, then CPU:</span>
<span class="k">if</span><span class="w"> </span>gpu_available:
<span class="w">    </span><span class="nv">device</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>torch.device<span class="o">(</span><span class="s1">'cuda'</span><span class="o">)</span>

<span class="k">elif</span><span class="w"> </span>tpu_available:<span class="w"> </span>
<span class="w">    </span>import<span class="w"> </span>torch_xla<span class="w"> </span>
<span class="w">    </span>import<span class="w"> </span>torch_xla.core.xla_model<span class="w"> </span>as<span class="w"> </span>xm
<span class="w">    </span><span class="nv">device</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>xm.xla_device<span class="o">()</span>

<span class="c1"># run this in a M1/M2 mac:</span>
<span class="k">elif</span><span class="w"> </span><span class="o">(</span>torch.backends.mps.is_available<span class="o">())</span><span class="w"> </span><span class="p">&amp;</span><span class="w"> </span><span class="o">(</span>torch.backends.mps.is_built<span class="o">())</span>:
<span class="w">    </span><span class="nv">device</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>torch.device<span class="o">(</span><span class="s2">"mps"</span><span class="o">)</span>

<span class="k">else</span>:
<span class="w">    </span><span class="nv">device</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>torch.device<span class="o">(</span><span class="s1">'cpu'</span><span class="o">)</span>

print<span class="o">(</span><span class="s2">"device in use:"</span>,<span class="w"> </span>device,<span class="w"> </span><span class="s2">"\n---"</span><span class="o">)</span>

<span class="c1"># Print GPU info if it is available:</span>
<span class="k">if</span><span class="w"> </span>gpu_available:
<span class="w">    </span>print<span class="o">(</span>os.popen<span class="o">(</span><span class="s2">"nvidia-smi"</span><span class="o">)</span>.read<span class="o">())</span>
</pre></div>
    </div>
    <aside class="postpromonav"><nav><ul itemprop="keywords" class="tags">
<li><a class="tag p-category" href="../../categories/code/" rel="tag">code</a></li>
            <li><a class="tag p-category" href="../../categories/colab/" rel="tag">colab</a></li>
            <li><a class="tag p-category" href="../../categories/python/" rel="tag">python</a></li>
            <li><a class="tag p-category" href="../../categories/pytorch/" rel="tag">pytorch</a></li>
        </ul>
<ul class="pager hidden-print">
<li class="previous">
                <a href="../rust-in-jupyter-notebooks/" rel="prev" title="How to add Rust support in Jupyter notebooks">Previous post</a>
            </li>
        </ul></nav></aside><section class="comments hidden-print"><h2>Comments</h2>
        
    
        <div id="disqus_thread"></div>
        <script>
        var disqus_shortname ="marcelo-tournier",
            disqus_url="https://marcelotournier.github.io/blog/how-to-setup-pytorch-to-run-in-gpus-tpus-or-m1m2-macs/",
        disqus_title="How to setup PyTorch to run in GPUs, TPUs or M1/M2 Macs",
        disqus_identifier="cache/posts/how-to-setup-pytorch-to-run-in-gpus-tpus-or-m1m2-macs.html",
        disqus_config = function () {
            this.language = "en";
        };
        (function() {
            var dsq = document.createElement('script'); dsq.async = true;
            dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script><noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a>
</noscript>
    <a href="https://disqus.com" class="dsq-brlink" rel="nofollow">Comments powered by <span class="logo-disqus">Disqus</span></a>


        </section></article><script>var disqus_shortname="marcelo-tournier";(function(){var a=document.createElement("script");a.async=true;a.src="https://"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(a)}());</script><!--End of body content--><footer id="footer">
            Contents © 2023         <a href="mailto:marcelo@inova.life">Marcelo Tournier</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
            
            
        </footer>
</div>
</div>


        <script src="../../assets/js/all-nocdn.js"></script><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
    </script>
</body>
</html>
